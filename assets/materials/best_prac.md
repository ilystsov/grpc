[Вернуться][main]

---

# Лучшие практики

Теперь у вас есть рабочая настройка микросервисов на Python. Вы можете создавать микросервисы, тестировать их вместе,
разворачивать в `Kubernetes` и отслеживать их с помощью перехватчиков. На этом этапе вы можете приступить к созданию
микросервисов. Однако вам следует помнить о некоторых лучших практиках, поэтому в этом разделе вы узнаете о некоторых из
них.

## Организация Protobuf

Как правило, вам следует хранить определения `protobuf` отдельно от реализации микросервиса. Клиенты могут быть написаны
практически на любом языке, и если вы упакуете свои файлы `protobuf` в колесо Python или что-то подобное, то если кто-то
захочет создать клиент на Ruby или Go, ему будет сложно получить файлы `protobuf`.

Даже если весь ваш код написан на Python, почему кто-то должен устанавливать пакет для микросервиса, чтобы написать для
него клиент?

Решение - поместить файлы `protobuf` в отдельное Git-репо от кода микросервиса. Многие компании размещают все файлы
`protobuf` для всех микросервисов в одном репо. Это облегчает поиск всех микросервисов, совместное использование общих
структур `protobuf` и создание полезных инструментов.

Если вы решите хранить файлы `protobuf` в одном репо, вам нужно следить за тем, чтобы репо оставалось организованным, и
избегать циклических зависимостей между микросервисами Python.

## Версионирование Protobuf

Версионирование API может быть сложной задачей, особенно потому, что при изменении API и обновлении микросервиса все еще
могут быть клиенты, использующие старую версию API. Это особенно актуально, когда клиенты установлены у пользователей,
например, на мобильных устройствах или десктопном ПО.

Принудить людей к обновлению непросто. Даже если бы это было возможно, задержки в сети могут привести к проблемам
синхронизации, и ваш микросервис может получать запросы, использующие старую версию API. Хорошее API должно быть либо
обратно совместимым, либо версионированным.

Для достижения обратной совместимости, микросервисы на Python, использующие protobuf версии 3, будут принимать запросы с
отсутствующими полями. Если вы хотите добавить новое поле, это возможно. Вы можете сначала развернуть микросервис, и он
все равно будет принимать запросы от старого API без нового поля. Главное, чтобы микросервис корректно обрабатывал такие
случаи.

Если вы хотите внести более радикальные изменения, вам нужно будет версионировать ваш API. Protobuf позволяет поместить
ваш API в пространство имен пакета, которое может включать номер версии. Если вам нужно коренным образом изменить API,
вы можете создать его новую версию. Микросервис сможет продолжать принимать и старую версию. Это позволяет постепенно
внедрять новую версию API, постепенно отказываясь от старой.

Следуя этим правилам, можно избежать внесения изменений, нарушающих совместимость. Внутри компании иногда считают, что
внесение таких изменений в API приемлемо, потому что они контролируют все клиенты. Однако стоит помнить, что внесение
изменений, нарушающих совместимость, требует скоординированного развертывания клиентов и микросервисов, что усложняет
откат изменений.

Это может быть приемлемо на очень раннем этапе жизненного цикла микросервиса, когда у него нет клиентов в производстве.
Однако, как только ваш микросервис становится критически важным для компании, хорошо войти в привычку вносить только
изменения, не нарушающие совместимость.

## Линтинг Protobuf

Чтобы не вносить в протобафы нежелательных изменений, можно использовать линтер. Популярным из них является `buf`. Вы
можете настроить его как часть вашей CI-системы, чтобы проверять наличие ломающих изменений в запросах на вытягивание.

## Проверка типов генерируемого Protobuf кода

`Mypy` - это проект для статической проверки типов в коде Python.

Код, генерируемый `protoc`, немного странный, и в нём нет аннотаций типов. Если вы попытаетесь проверить его с помощью
`Mypy`, то получите множество ошибок, и он не сможет отловить настоящие ошибки, такие как неправильное написание имен
полей. К счастью, добрые люди из `Dropbox` написали плагин для компилятора `protoc`, который генерирует заглушки типов.
Не
следует путать их с заглушками `gRPC`.

Чтобы использовать его, вы можете установить пакет `mypy-protobuf`, а затем обновить команду для генерации вывода
`protobuf`. Обратите внимание на новую опцию `--mypy_out`:

```sh
python -m grpc_tools.protoc -I ../protobufs --python_out=. --grpc_python_out=. --mypy_out=. ../protobufs/recommendations.proto
```

Большинство ошибок `Mypy` должно исчезнуть. Вы все еще можете получить ошибку о том, что пакет `grpc` не имеет
информации о
типе. Вы можете либо установить неофициальные заглушки типов `gRPC`, либо добавить в конфигурацию `Mypy` следующее:

```config
[mypy-grpc.*]
ignore_missing_imports = True
```

Вы по-прежнему будете получать большинство преимуществ проверки типов, например, отлавливать неправильно написанные
поля. Это очень полезно для отлова ошибок до того, как они попадут в прод.

## Грациозное завершение работы - Graceful ShutDown

Когда микросервис запущен на машине разработки, вы можете нажать `Ctrl+C`, чтобы остановить его. Это приведет к тому,
что
интерпретатор Python вызовет исключение `KeyboardInterrupt`.

Когда `Kubernetes` запускает ваш микросервис и должен остановить его, чтобы выпустить обновление, он отправит сигнал
вашему микросервису. В частности, он отправит сигнал `SIGTERM` и подождет тридцать секунд. Если к этому времени ваш
микросервис не завершится, он отправит сигнал `SIGKILL`.

Вы можете и должны перехватить и обработать сигнал `SIGTERM`, чтобы завершить обработку текущих запросов и отклонить
новые. Это можно сделать, поместив следующий код в `serve()`:

```python
from signal import signal, SIGTERM

...


def serve():
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    ...
    server.add_insecure_port("[::]:50051")
    server.start()

    def handle_sigterm(*_):
        print("Received shutdown signal")
        all_rpcs_done_event = server.stop(30)
        all_rpcs_done_event.wait(30)
        print("Shut down gracefully")

    signal(SIGTERM, handle_sigterm)
    server.wait_for_termination()
```

Вот как это делается:

- В строке 1 импортируется `signal`, которая позволяет перехватывать и обрабатывать сигналы от `Kubernetes` или почти
  любого
  другого процесса.
- В строке 11 определена функция для обработки `SIGTERM`. Функция будет вызываться, когда `Python` получит
  сигнал `SIGTERM`, и
  `Python` передаст ей два аргумента. Однако вам эти аргументы не нужны, поэтому используйте *_, чтобы проигнорировать
  их
  оба.
- В строке 13 вызывается `server.stop(30)`, чтобы изящно завершить работу сервера. Он отклонит новые запросы и подождет
  30
  секунд, пока завершатся текущие запросы. Он возвращается немедленно, но возвращает объект threading.Event, на котором
  вы можете подождать.
- Строка 14 ждет объект `Event`, чтобы Python не завершился преждевременно.
- Строка 17 регистрирует ваш обработчик.

Когда вы развертываете новую версию своего микросервиса, `Kubernetes` будет посылать сигналы для отключения
существующего
микросервиса. Обработка этих сигналов для изящного завершения работы позволит избежать потери запроса.

## Защита каналов

До сих пор вы использовали небезопасные каналы `gRPC`. Это означает несколько вещей:

1. Клиент не может убедиться, что отправляет запросы на нужный сервер. Кто-то может создать самозваный микросервис и
   внедрить его куда-нибудь, куда клиент может отправить запрос. Например, они могут внедрить микросервис в капсулу, на
   которую балансировщик нагрузки будет отправлять запросы.

2. Сервер не может подтвердить, что клиент отправляет ему запросы. Пока кто-то может подключиться к серверу, он может
   отправлять ему произвольные gRPC-запросы.

3. Трафик не шифруется, поэтому любые узлы, маршрутизирующие трафик, могут его просматривать.

В этом разделе описано, как добавить аутентификацию и шифрование TLS.

> Примечание: здесь не рассматривается аутентификация пользователей, а только процессов микросервисов.

Вы узнаете два способа настройки TLS:

1. Простой способ, при котором клиент может проверить сервер, а сервер не проверяет клиента.
2. Более сложный способ - взаимный TLS, при котором клиент и сервер проверяют друг друга.

В обоих случаях трафик шифруется.

## Основы TLS

Прежде чем погрузиться в эту тему, приведем краткий обзор TLS: Как правило, клиент проверяет сервер. Например, когда вы
заходите на сайт Amazon.com, ваш браузер проверяет, действительно ли это Amazon.com, а не самозванец. Для этого клиент
должен получить некую гарантию от надежной третьей стороны, наподобие того, как вы можете доверять новому человеку,
только если у вас есть общий друг, который за него поручился.

В TLS клиент должен доверять центру сертификации (ЦС). ЦС подписывает что-то, хранящееся на сервере, чтобы клиент мог
это проверить. Это похоже на то, как если бы ваш общий друг подписал записку, а вы узнали его почерк. Дополнительные
сведения см. в разделе Как работает интернет-безопасность: TLS, SSL и CA.

Ваш браузер неявно доверяет некоторым ЦС, которые обычно являются компаниями вроде GoDaddy, DigiCert или Verisign.
Другие компании, например Amazon, платят ЦС за подписание цифрового сертификата для них, поэтому ваш браузер доверяет
им. Как правило, перед подписанием сертификата центр сертификации проверяет, что Amazon владеет сайтом Amazon.com. Таким
образом, у мошенника не будет подписи на сертификате Amazon.com, и ваш браузер заблокирует сайт.

В случае с микросервисами вы не можете попросить ЦС подписать сертификат, поскольку ваши микросервисы работают на
внутренних машинах. ЦС, вероятно, будет рад подписать сертификат и взять за это деньги, но дело в том, что это
непрактично. В этом случае ваша компания может выступить в роли собственного ЦС. Клиент gRPC будет доверять серверу,
если у него есть сертификат, подписанный вашей компанией или вами, если вы занимаетесь личным проектом.

## Аутентификация сервера

Следующая команда создаст сертификат ЦС, который можно использовать для подписи сертификата сервера:

```sh
openssl req -x509 -nodes -newkey rsa:4096 -keyout ca.key -out ca.pem -subj /O=me
```

Это приведет к созданию двух файлов:

1. ca.key - закрытый ключ.
2. ca.pem - публичный сертификат.

Затем вы можете создать сертификат для своего сервера и подписать его сертификатом центра сертификации:

```sh
openssl req -nodes -newkey rsa:4096 -keyout server.key -out server.csr \
              -subj /CN=рекомендации
openssl x509 -req -in server.csr -CA ca.pem -CAkey ca.key -set_serial 1 \
              -out server.pem
```

В результате будут созданы три новых файла:

1. server.key - закрытый ключ сервера.
2. server.csr - промежуточный файл.
3. server.pem - открытый сертификат сервера.

> Примечание: Эти команды приведены только для примера. Закрытые ключи не зашифрованы. Если вы хотите сгенерировать
> сертификаты для своей компании, обратитесь к специалистам по безопасности. Скорее всего, у них есть политики по
> созданию, хранению и отзыву сертификатов, которым вы должны следовать.

Вы можете добавить это в `Dockerfile` микросервиса `Recommendations`. Раньше было сложно безопасно добавить секреты в
образ
`Docker`, но в последних версиях `Docker` есть способ сделать это, как показано ниже:

```Dockerfile
# syntax = docker/dockerfile:1.0-experimental
# DOCKER_BUILDKIT=1 docker build . -f recommendations/Dockerfile \
#                     -t recommendations --secret id=ca.key,src=ca.key

FROM python

RUN mkdir /service
COPY infra/ /service/infra/
COPY protobufs/ /service/protobufs/
COPY recommendations/ /service/recommendations/
COPY ca.pem /service/recommendations/

WORKDIR /service/recommendations
RUN python -m pip install --upgrade pip
RUN python -m pip install -r requirements.txt
RUN python -m grpc_tools.protoc -I ../protobufs --python_out=. \
           --grpc_python_out=. ../protobufs/recommendations.proto
RUN openssl req -nodes -newkey rsa:4096 -subj /CN=recommendations \
                -keyout server.key -out server.csr
RUN --mount=type=secret,id=ca.key \
    openssl x509 -req -in server.csr -CA ca.pem -CAkey /run/secrets/ca.key \
                 -set_serial 1 -out server.pem

EXPOSE 50051
ENTRYPOINT [ "python", "recommendations.py" ]
```

Что изменилось:

- Строка 1 нужна для включения секретов.
- Строки 2 и 3 показывают команду для создания образа Docker.
- Строка 11 копирует публичный сертификат ЦС в образ.
- В строках 18 и 19 генерируется новый закрытый ключ и сертификат сервера.
- В строках 20-22 временно загружается закрытый ключ ЦС, чтобы вы могли подписать им сертификат сервера. Однако он не
  будет сохранен в образе.

> Примечание: Более подробную информацию о параметре `--mount=type=secret` см. в документации Docker. В будущем эта
> функция может быть перенесена в стабильный релиз, и тогда вам не нужно будет включать в `Dockerfile` комментарий
> `syntax = docker/dockerfile:1.0-experimental`
>
> Согласно политике версионирования, экспериментальный синтаксис не исчезнет, поэтому вы можете продолжать использовать
> его неограниченное время.

Теперь ваш образ будет содержать следующие файлы:

- ca.pem
- server.csr
- server.key
- server.pem

Теперь вы можете обновить функцию `serve()` в файле `recommendations.py`, как показано ниже:

```py
def serve():
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    recommendations_pb2_grpc.add_RecommendationsServicer_to_server(
        RecommendationService(), server
    )

    with open("server.key", "rb") as fp:
        server_key = fp.read()
    with open("server.pem", "rb") as fp:
        server_cert = fp.read()

    creds = grpc.ssl_server_credentials([(server_key, server_cert)])
    server.add_secure_port("[::]:443", creds)
    server.start()
    server.wait_for_termination()
```

Вот изменения:

- Строки 7-10 загружают закрытый ключ и сертификат сервера.
- Строки 12 и 13 запускают сервер с использованием TLS. Теперь он будет принимать только TLS-шифрованные соединения.

Вам нужно будет обновить `marketplace.py`, чтобы загрузить сертификат центра сертификации. В клиенте пока нужен только
публичный сертификат, как показано ниже:

```py
recommendations_host = os.getenv("RECOMMENDATIONS_HOST", "localhost")
with open("ca.pem", "rb") as fp:
    ca_cert = fp.read()
creds = grpc.ssl_channel_credentials(ca_cert)
recommendations_channel = grpc.secure_channel(
    f"{recommendations_host}:443", creds
)
recommendations_client = RecommendationsStub(recommendations_channel)
```

Вам также нужно будет добавить `COPY ca.pem /service/marketplace/` в `Dockerfile` `Marketplace`.

Теперь вы можете запустить клиент и сервер с шифрованием, и клиент подтвердит сервер. Чтобы упростить запуск, можно
использовать `docker-compose`. Старые версии `docker-compose` не поддерживали секреты сборки. Если используете не
актуальные версию - вам
придется собирать образы `Docker` вручную, а не с помощью `docker-compose build`.

Однако вы все равно можете запустить `docker-compose up`. Обновите файл `docker-compose.yaml`, чтобы удалить секции
сборки:

```yaml
version: "3.8"
services:

  marketplace:
    environment:
      RECOMMENDATIONS_HOST: recommendations
    # DOCKER_BUILDKIT=1 docker build . -f marketplace/Dockerfile \
    #                   -t marketplace --secret id=ca.key,src=ca.key
    image: marketplace
    networks:
      - microservices
    ports:
      - 5000:5000

  recommendations:
    # DOCKER_BUILDKIT=1 docker build . -f recommendations/Dockerfile \
    #                   -t recommendations --secret id=ca.key,src=ca.key
    image: recommendations
    networks:
      - microservices

networks:
  microservices:
```

Теперь вы шифруете трафик и проверяете, что подключаетесь к нужному серверу.

## Взаимная аутентификация

Теперь сервер доказывает, что ему можно доверять, а клиент - нет. К счастью, `TLS` позволяет проверить обе стороны.
Обновите `Dockerfile` `Marketplace`, как показано ниже:

```Dockerfile
# syntax = docker/dockerfile:1.0-experimental
# DOCKER_BUILDKIT=1 docker build . -f marketplace/Dockerfile \
#                     -t marketplace --secret id=ca.key,src=ca.key

FROM python

RUN mkdir /service
COPY protobufs/ /service/protobufs/
COPY marketplace/ /service/marketplace/
COPY ca.pem /service/marketplace/

WORKDIR /service/marketplace
RUN python -m pip install -r requirements.txt
RUN python -m grpc_tools.protoc -I ../protobufs --python_out=. \
           --grpc_python_out=. ../protobufs/recommendations.proto
RUN openssl req -nodes -newkey rsa:4096 -subj /CN=marketplace \
                -keyout client.key -out client.csr
RUN --mount=type=secret,id=ca.key \
    openssl x509 -req -in client.csr -CA ca.pem -CAkey /run/secrets/ca.key \
                 -set_serial 1 -out client.pem

EXPOSE 5000
ENV FLASK_APP=marketplace.py
ENTRYPOINT [ "flask", "run", "--host=0.0.0.0"]
```

Эти изменения аналогичны тем, которые вы сделали для микросервиса "Рекомендации" в предыдущем разделе.

Примечание: Если вы помещаете закрытые ключи в `Docker`-файлы, то не размещайте их в общедоступном хранилище. Лучше
загружать закрытые ключи во время выполнения, по сети, с сервера, доступного только через VPN.

Обновите `serve()` в `recommendations.py`, чтобы аутентифицировать клиента, как выделено:

```py
def serve():
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    recommendations_pb2_grpc.add_RecommendationsServicer_to_server(
        RecommendationService(), server
    )

    with open("server.key", "rb") as fp:
        server_key = fp.read()
    with open("server.pem", "rb") as fp:
        server_cert = fp.read()
    with open("ca.pem", "rb") as fp:
        ca_cert = fp.read()

    creds = grpc.ssl_server_credentials(
        [(server_key, server_cert)],
        root_certificates=ca_cert,
        require_client_auth=True,
    )
    server.add_secure_port("[::]:443", creds)
    server.start()
    server.wait_for_termination()
```

Это загрузит сертификат ЦС и потребует аутентификации клиента.

Наконец, обновите `marketplace.py`, чтобы отправить свой сертификат на сервер, как показано ниже:

```py
recommendations_host = os.getenv("RECOMMENDATIONS_HOST", "localhost")
with open("client.key", "rb") as fp:
    client_key = fp.read()
with open("client.pem", "rb") as fp:
    client_cert = fp.read()
with open("ca.pem", "rb") as fp:
    ca_cert = fp.read()
creds = grpc.ssl_channel_credentials(ca_cert, client_key, client_cert)
recommendations_channel = grpc.secure_channel(
    f"{recommendations_host}:443", creds
)
recommendations_client = RecommendationsStub(recommendations_channel)
```

Это загружает сертификаты и отправляет их на сервер для проверки.

Теперь, если вы попытаетесь подключиться к серверу с помощью другого клиента, даже использующего `TLS`, но с неизвестным
сертификатом, сервер отклонит его с ошибкой `PEER_DID_NOT_RETURN_A_CERTIFICATE`.

Важно: Хотя управлять взаимным `TLS` таким образом можно, сделать это непросто. Особенно сложно это становится, если вы
хотите разрешить только определенным микросервисам делать запросы к другим.

Если у вас есть потребность в повышенной безопасности, вероятно, лучше использовать сервисную сетку и позволить ей
управлять сертификатами и авторизацией за вас. В дополнение к мониторингу трафика, упомянутому в разделе о
перехватчиках, `Istio` может управлять взаимным `TLS` и авторизацией для каждого сервиса. Это также более безопасно,
поскольку он будет управлять секретами за вас и чаще перевыпускать сертификаты.

На этом защита связи между микросервисами завершена. Далее вы узнаете об использовании `AsyncIO` с микросервисами.

---

[Вернуться][main]


[main]: ../../README.md "содержание"

